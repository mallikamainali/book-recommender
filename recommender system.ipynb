{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9639181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your favorite book:Harry Potter and the Chamber of Secrets\n",
      "Recommendations based on Harry Potter and the Chamber of Secrets:\n",
      "1: The Return of the King, distance: 0.5137453857083071\n",
      "2: Mockingjay, distance: 0.484811069871498\n",
      "3: The Da Vinci Code, distance: 0.48437188831920774\n",
      "4: Catching Fire, distance: 0.46678667832629206\n",
      "5: Harry Potter and the Philosopher's Stone, distance: 0.4454417431428892\n",
      "6: Harry Potter and the Deathly Hallows, distance: 0.2774345523014743\n",
      "7: Harry Potter and the Half-Blood Prince, distance: 0.21458444953407796\n",
      "8: Harry Potter and the Order of the Phoenix, distance: 0.17345094201226208\n",
      "9: Harry Potter and the Goblet of Fire, distance: 0.1489778170737216\n",
      "10: Harry Potter and the Prisoner of Azkaban, distance: 0.1395682125920943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Return of the King',\n",
       " 'Mockingjay',\n",
       " 'The Da Vinci Code',\n",
       " 'Catching Fire',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Harry Potter and the Half-Blood Prince',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Prisoner of Azkaban']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import necessary libariries to build the recommender system based on collaborative filtering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.sparse import csr_matrix\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Read the books, ratings, tags, and btags data from goodreads dataset\n",
    "books= pd.read_csv(\"books.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "tags = pd.read_csv(\"book_tags.csv\")\n",
    "btags = pd.read_csv(\"tags.csv\")\n",
    "\n",
    "#Clean data\n",
    "#Remove duplicates\n",
    "ratings=ratings.sort_values(\"user_id\")\n",
    "ratings.drop_duplicates(subset =[\"user_id\",\"book_id\"], keep = False, inplace = True) \n",
    "books.drop_duplicates(subset='original_title',keep=False,inplace=True)\n",
    "btags.drop_duplicates(subset='tag_id',keep=False,inplace=True)\n",
    "tags.drop_duplicates(subset=['tag_id','goodreads_book_id'],keep=False,inplace=True)\n",
    "\n",
    "#Drop the null values\n",
    "books_col_no_null=['book_id', 'original_title']\n",
    "books_updated_col=books[books_col_no_null]\n",
    "\n",
    "#Create Compressed sparse row matrix\n",
    "#Pivot the ratings into features\n",
    "matrix_book_features = ratings.pivot(index='book_id',columns='user_id',values='rating').fillna(0)\n",
    "book_features = csr_matrix(matrix_book_features.values)\n",
    "\n",
    "#Use the K nearest neighbors algorithm to find the nearest book with least distance available\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "ratings=ratings.dropna()\n",
    "ratings_count = pd.DataFrame(ratings.groupby('rating').size(), columns=['count'])\n",
    "\n",
    "bookid_userid_length = len(ratings.user_id.unique()) * len(ratings.book_id.unique())\n",
    "rating_zero_cnt = bookid_userid_length - ratings.shape[0]\n",
    "\n",
    "ratings_calc = ratings_count.append(\n",
    "    pd.DataFrame({'count': rating_zero_cnt}, index=[0.0]),\n",
    "    verify_integrity=True,\n",
    ").sort_index()\n",
    "\n",
    "#Remove books that are rated 0 or unrated\n",
    "books_count = pd.DataFrame(ratings.groupby('book_id').size(), columns=['count'])\n",
    "\n",
    "#Set the popularity threshold to 60 to take books that have been rated at least 60 times \n",
    "popularity_threshold = 60\n",
    "popular_movies = list(set(books_count.query('count >= @popularity_threshold').index))\n",
    "popular_movies_ratings = ratings[ratings.book_id.isin(popular_movies)]\n",
    "\n",
    "#Get the number of ratings given by every user\n",
    "ratings_users_count = pd.DataFrame(popular_movies_ratings.groupby('user_id').size(), columns=['count'])\n",
    "\n",
    "ratings_thres = 50\n",
    "active_users = list(set(ratings_users_count.query('count >= @ratings_thres').index))\n",
    "popular_movies_ratings_users = popular_movies_ratings[popular_movies_ratings.user_id.isin(active_users)]\n",
    "\n",
    "user_matrix = popular_movies_ratings_users.pivot(index='book_id', columns='user_id', values='rating').fillna(0)\n",
    "user_matrix_sparse = csr_matrix(user_matrix.values)\n",
    "\n",
    "#Knn algorithm\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "knn_model.fit(user_matrix_sparse)\n",
    "\n",
    "def fuzzy_match(mapper, fav_book, verbose=True):\n",
    "    match_books = []\n",
    "    #Get book match\n",
    "    for title, index in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_book.lower())\n",
    "        if ratio >= 60:\n",
    "            match_books.append((title, index, ratio))\n",
    "    #Sort the recommendation values\n",
    "    match_books = sorted(match_books, key=lambda x: x[2])[::-1]\n",
    "    if not match_books:\n",
    "        return\n",
    "    if verbose:\n",
    "        return match_books[0][1]\n",
    "\n",
    "#Recommend books using collaborative filtering based on the user's input\n",
    "def make_recommendation(knn_model, data, mapper, fav_book, n_recommendations):\n",
    "    knn_model.fit(data)\n",
    "    \n",
    "    #Get input movie index\n",
    "    index = fuzzy_match(mapper, fav_book, verbose=True)\n",
    "    distances, indices = knn_model.kneighbors(data[index], n_neighbors=n_recommendations+1)\n",
    "    \n",
    "    raw_recommendations = sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    #Map reverse\n",
    "    reverse_map = {v: k for k, v in mapper.items()}\n",
    "    #Print book recommendations\n",
    "    print('Recommendations based on {}:'.format(fav_book))\n",
    "    \n",
    "    rec=[]\n",
    "    for i, (index, dist) in enumerate(raw_recommendations):\n",
    "        if index not in reverse_map.keys():\n",
    "            continue\n",
    "        print('{0}: {1}, distance: {2}'.format(i+1, reverse_map[index], dist))\n",
    "        rec.append(reverse_map[index])\n",
    "    return rec\n",
    "\n",
    "user_favorite = input(\"Enter your favorite book:\")\n",
    "indices = pd.Series(books_updated_col.index, index=books_updated_col['original_title'])\n",
    "\n",
    "make_recommendation(\n",
    "    knn_model=knn_model,\n",
    "    data=user_matrix_sparse,\n",
    "    fav_book=user_favorite,\n",
    "    mapper=indices,\n",
    "    n_recommendations=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e12322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3e4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
